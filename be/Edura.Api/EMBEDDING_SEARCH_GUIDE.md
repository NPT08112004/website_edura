# üîç H∆∞·ªõng d·∫´n Embedding-based Semantic Search

## üìã T·ªïng quan

H·ªá th·ªëng search d·ª±a tr√™n **embedding vectors** (semantic search) cho ph√©p t√¨m ki·∫øm theo **√Ω nghƒ©a** thay v√¨ ch·ªâ match t·ª´ kh√≥a.

**∆Øu ƒëi·ªÉm:**
- ‚úÖ **Semantic understanding**: Hi·ªÉu ƒë∆∞·ª£c √Ω nghƒ©a c·ªßa query
- ‚úÖ **T√¨m ki·∫øm t∆∞∆°ng t·ª±**: T√¨m ƒë∆∞·ª£c documents t∆∞∆°ng t·ª± d√π kh√¥ng c√≥ t·ª´ kh√≥a ch√≠nh x√°c
- ‚úÖ **H·ªó tr·ª£ ti·∫øng Vi·ªát**: S·ª≠ d·ª•ng model ƒë∆∞·ª£c train cho ti·∫øng Vi·ªát
- ‚úÖ **Kh√¥ng c·∫ßn API key**: Ch·∫°y local v·ªõi sentence-transformers

**V√≠ d·ª•:**
- Query: "to√°n h·ªçc" ‚Üí T√¨m ƒë∆∞·ª£c: "Gi·∫£i t√≠ch", "ƒê·∫°i s·ªë", "To√°n cao c·∫•p"
- Query: "l·∫≠p tr√¨nh" ‚Üí T√¨m ƒë∆∞·ª£c: "Coding", "Programming", "Ph√°t tri·ªÉn ph·∫ßn m·ªÅm"

---

## üöÄ Setup

### 1. C√†i ƒë·∫∑t dependencies

```bash
pip install sentence-transformers numpy
```

Ho·∫∑c th√™m v√†o `requirements.txt`:
```
sentence-transformers>=2.2.0
numpy>=1.24.0
```

### 2. C·∫•u h√¨nh Environment Variables

**C√°ch 1: Th√™m v√†o file `.env` (Khuy·∫øn ngh·ªã)**

M·ªü file `.env` trong th∆∞ m·ª•c `be/Edura.Api/` v√† th√™m:

```env
# Enable embedding search
USE_EMBEDDING_SEARCH=true

# Model name (optional, c√≥ default)
EMBEDDING_MODEL_NAME=keepitreal/vietnamese-sbert

# Vector search parameters (optional)
VECTOR_SEARCH_THRESHOLD=0.3  # Minimum similarity (0-1)
VECTOR_SEARCH_TOP_K=100      # Top K results
```

**C√°ch 2: Set environment variable t·∫°m th·ªùi (ch·ªâ cho session hi·ªán t·∫°i)**

```powershell
# Windows PowerShell
$env:USE_EMBEDDING_SEARCH="true"
$env:EMBEDDING_MODEL_NAME="keepitreal/vietnamese-sbert"
```

```cmd
# Windows CMD
set USE_EMBEDDING_SEARCH=true
set EMBEDDING_MODEL_NAME=keepitreal/vietnamese-sbert
```

```bash
# Linux/Mac
export USE_EMBEDDING_SEARCH=true
export EMBEDDING_MODEL_NAME=keepitreal/vietnamese-sbert
```

**L∆∞u √Ω:** C√°ch 1 (file `.env`) ƒë∆∞·ª£c khuy·∫øn ngh·ªã v√¨:
- ‚úÖ Persistent (kh√¥ng m·∫•t khi ƒë√≥ng terminal)
- ‚úÖ D·ªÖ qu·∫£n l√Ω v√† version control (th√™m `.env` v√†o `.gitignore`)
- ‚úÖ T·ª± ƒë·ªông load khi ch·∫°y Flask app

### 3. Generate embeddings cho documents hi·ªán c√≥

```bash
python scripts/generate_document_embeddings.py
```

Script n√†y s·∫Ω:
- Load t·∫•t c·∫£ documents t·ª´ MongoDB
- Generate embeddings cho m·ªói document
- L∆∞u embeddings v√†o MongoDB field `embedding`

**L∆∞u √Ω:**
- L·∫ßn ƒë·∫ßu ch·∫°y s·∫Ω download model (c√≥ th·ªÉ m·∫•t v√†i ph√∫t)
- V·ªõi dataset l·ªõn, c√≥ th·ªÉ m·∫•t th·ªùi gian
- C√≥ th·ªÉ ch·∫°y l·∫°i ƒë·ªÉ update embeddings cho documents m·ªõi

---

## üèóÔ∏è Ki·∫øn tr√∫c

### Files ƒë√£ t·∫°o:

1. **`app/services/embedding_service.py`**
   - Generate embeddings cho text/queries
   - S·ª≠ d·ª•ng sentence-transformers
   - Lazy load model (singleton)

2. **`app/services/vector_search_service.py`**
   - Vector search b·∫±ng cosine similarity
   - L∆∞u/load embeddings t·ª´ MongoDB
   - Hybrid search (vector + keyword)

3. **`scripts/generate_document_embeddings.py`**
   - Script generate embeddings cho documents hi·ªán c√≥

### Lu·ªìng ho·∫°t ƒë·ªông:

```
Query ‚Üí Generate Query Embedding ‚Üí Load Document Embeddings 
‚Üí Calculate Cosine Similarity ‚Üí Filter by Threshold ‚Üí Sort by Similarity ‚Üí Results
```

---

## üîß S·ª≠ d·ª•ng

### Option 1: Pure Vector Search

Ch·ªâ s·ª≠ d·ª•ng vector similarity:

```python
from app.services.vector_search_service import VectorSearchService

results = VectorSearchService.search_by_vector(
    query="to√°n h·ªçc",
    documents=all_documents,
    category_map=category_map,
    top_k=10
)
```

### Option 2: Hybrid Search (Khuy·∫øn ngh·ªã)

K·∫øt h·ª£p vector similarity + keyword-based scores:

```python
from app.services.vector_search_service import VectorSearchService

# T√≠nh keyword scores tr∆∞·ªõc
keyword_scores = {...}  # doc_id -> score

# Hybrid search
results = VectorSearchService.hybrid_search(
    query="to√°n h·ªçc",
    documents=all_documents,
    category_map=category_map,
    keyword_scores=keyword_scores,
    vector_weight=0.6,  # 60% vector
    keyword_weight=0.4  # 40% keyword
)
```

### Option 3: T√≠ch h·ª£p v√†o SearchService

ƒê√£ ƒë∆∞·ª£c t√≠ch h·ª£p t·ª± ƒë·ªông v√†o `SearchService.calculate_relevance()`:
- N·∫øu `USE_EMBEDDING_SEARCH=true` ‚Üí S·ª≠ d·ª•ng vector search
- N·∫øu kh√¥ng ‚Üí Fallback v·ªÅ BM25 ho·∫∑c keyword-based

---

## üìä Models h·ªó tr·ª£

### Vietnamese Models:

1. **`keepitreal/vietnamese-sbert`** (Default)
   - Model t·ªët cho ti·∫øng Vi·ªát
   - Dimension: 768
   - Fast v√† accurate

2. **`VoVanPhuc/sup-SimCSE-VietNamese-phobert-base`**
   - Model chuy√™n cho ti·∫øng Vi·ªát
   - Dimension: 768
   - C√≥ th·ªÉ t·ªët h∆°n cho m·ªôt s·ªë use cases

3. **`sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`**
   - Multilingual (h·ªó tr·ª£ nhi·ªÅu ng√¥n ng·ªØ)
   - Dimension: 384
   - Nh·ªè h∆°n, nhanh h∆°n

### C√°ch ch·ªçn model:

```env
# Model t·ªët cho ti·∫øng Vi·ªát (khuy·∫øn ngh·ªã)
EMBEDDING_MODEL_NAME=keepitreal/vietnamese-sbert

# Model nh·ªè, nhanh (cho production)
EMBEDDING_MODEL_NAME=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
```

---

## ‚öôÔ∏è Tuning Parameters

### `VECTOR_SEARCH_THRESHOLD` (0.3 default)

- **√ù nghƒ©a**: Minimum cosine similarity ƒë·ªÉ ch·∫•p nh·∫≠n document
- **Range**: 0.0 - 1.0
- **TƒÉng** (0.5-0.7): Ch·ªâ tr·∫£ v·ªÅ documents r·∫•t t∆∞∆°ng t·ª± (√≠t k·∫øt qu·∫£, ch√≠nh x√°c h∆°n)
- **Gi·∫£m** (0.1-0.2): Tr·∫£ v·ªÅ nhi·ªÅu k·∫øt qu·∫£ h∆°n (c√≥ th·ªÉ c√≥ false positives)

### `VECTOR_SEARCH_TOP_K` (100 default)

- **√ù nghƒ©a**: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ t·ªëi ƒëa
- **TƒÉng**: Nhi·ªÅu k·∫øt qu·∫£ h∆°n (ch·∫≠m h∆°n)
- **Gi·∫£m**: √çt k·∫øt qu·∫£ h∆°n (nhanh h∆°n)

---

## üîÑ Auto-generate Embeddings

Khi upload document m·ªõi, embedding s·∫Ω ƒë∆∞·ª£c generate t·ª± ƒë·ªông (n·∫øu enabled).

Khi search, n·∫øu document ch∆∞a c√≥ embedding:
- Generate embedding on-the-fly
- L∆∞u v√†o MongoDB ƒë·ªÉ d√πng l·∫°i

---

## üìà Performance

### So s√°nh:

| Metric | Keyword-based | BM25 | Vector Search |
|--------|---------------|------|---------------|
| **Accuracy** | Trung b√¨nh | T·ªët | R·∫•t t·ªët (semantic) |
| **Speed** | R·∫•t nhanh | Nhanh | Ch·∫≠m h∆°n (c·∫ßn t√≠nh embedding) |
| **Memory** | Th·∫•p | Trung b√¨nh | Cao (l∆∞u embeddings) |
| **Setup** | D·ªÖ | D·ªÖ | C·∫ßn generate embeddings |

### T·ªëi ∆∞u:

1. **Pre-generate embeddings**: Ch·∫°y script m·ªôt l·∫ßn cho t·∫•t c·∫£ documents
2. **Cache embeddings**: L∆∞u trong MongoDB ƒë·ªÉ kh√¥ng ph·∫£i t√≠nh l·∫°i
3. **Batch processing**: Generate embeddings theo batch
4. **Hybrid search**: K·∫øt h·ª£p vector + keyword ƒë·ªÉ c√¢n b·∫±ng accuracy v√† speed

---

## üß™ Testing

### Test embedding generation:

```python
from app.services.embedding_service import generate_embedding, cosine_similarity

# Generate embeddings
emb1 = generate_embedding("to√°n h·ªçc")
emb2 = generate_embedding("gi·∫£i t√≠ch")

# Calculate similarity
similarity = cosine_similarity(emb1, emb2)
print(f"Similarity: {similarity}")  # Should be high (> 0.7)
```

### Test vector search:

```python
from app.services.vector_search_service import VectorSearchService

# Search
results = VectorSearchService.search_by_vector(
    query="to√°n h·ªçc",
    documents=documents,
    category_map=category_map
)

for doc, score in results:
    print(f"{doc['title']}: {score:.2f}")
```

---

## üö® Troubleshooting

### Model kh√¥ng load ƒë∆∞·ª£c

```bash
# Ki·ªÉm tra c√†i ƒë·∫∑t
pip install sentence-transformers

# Ki·ªÉm tra model name
# Th·ª≠ model kh√°c n·∫øu model hi·ªán t·∫°i kh√¥ng available
```

### Embeddings qu√° l·ªõn

- Gi·∫£m `EMBEDDING_DIMENSION` (n·∫øu d√πng model nh·ªè h∆°n)
- Ho·∫∑c s·ª≠ d·ª•ng model nh·ªè h∆°n (384 dimension thay v√¨ 768)

### Performance ch·∫≠m

1. **Pre-generate embeddings**: Ch·∫°y script m·ªôt l·∫ßn
2. **Use smaller model**: Model 384 dimension thay v√¨ 768
3. **Increase threshold**: Gi·∫£m s·ªë documents c·∫ßn t√≠nh similarity
4. **Use hybrid search**: K·∫øt h·ª£p v·ªõi keyword search

---

## üìö References

- [Sentence Transformers](https://www.sbert.net/)
- [Hugging Face Models](https://huggingface.co/models?library=sentence-transformers)
- [Vietnamese SBERT](https://huggingface.co/keepitreal/vietnamese-sbert)
- [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)

---

## ‚úÖ Checklist

- [ ] C√†i ƒë·∫∑t `sentence-transformers` v√† `numpy`
- [ ] Set `USE_EMBEDDING_SEARCH=true` trong `.env`
- [ ] Ch·∫°y `generate_document_embeddings.py` ƒë·ªÉ t·∫°o embeddings
- [ ] Test v·ªõi queries kh√°c nhau
- [ ] Tune parameters `VECTOR_SEARCH_THRESHOLD` v√† `VECTOR_SEARCH_TOP_K`
- [ ] Monitor performance v√† memory usage
- [ ] Deploy v·ªõi embeddings ƒë√£ generate

